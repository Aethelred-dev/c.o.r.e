/**
 * @file core_engine_v7_hardened.c
 * @author C.O.R.E. Development (Hardened by Review)
 * @date 2024
 * @version 7.0.0
 * @brief Hardened, Production-Ready Cognitive Orthogonal Reasoning Engine.
 *
 * This version is a major refactoring, addressing a comprehensive list of architectural and
 * concurrency-related issues identified in review. It is engineered for absolute
 * state integrity, high-throughput concurrent access, and verifiable, deterministic reasoning.
 *
 * COMPILE (with Pthreads and AVX2 for performance):
 *   gcc -O3 -Wall -Wextra -pthread -mavx2 -o core_engine_hardened core_engine_v7_hardened.c
 *
 * ARCHITECTURAL FIXES & FEATURES (VERSION 7.0.0):
 *
 *  ‚úÖ FIX: (Semantic Collapse) The Gravitational Engine now respects a configurable
 *         `min_gravitational_distance` to prevent concepts from becoming identical,
 *         which would lead to semantic collapse. This preserves conceptual entropy.
 *
 *  ‚úÖ FIX: (Concurrency) The global `concept_count` is now correctly protected by the
 *         `resize_lock` during all increments and decrements, preventing race conditions
 *         that could lead to an inaccurate count.
 *
 *  ‚úÖ FIX: (Concurrency) The `kb_resize` function is now fully thread-safe. It performs a
 *         "stop-the-world" operation by acquiring all old bucket locks before re-hashing,
 *         eliminating a critical race condition where other threads could access a
 *         partially rebuilt or freed hash table.
 * 
 *  ‚úÖ FIX: (Persistence) Implemented robust, thread-safe `core_kb_save` and `core_kb_load`
 *         functions, replacing the previous placeholders. The system can now serialize its
 *         source of truth (the assertion log) and deterministically reconstruct its state.
 *
 *  ‚úÖ DOC: (Architectural Choice: XOR Binding) Acknowledged that XOR-binding is a
 *         deliberate design choice for simplicity. A production system would use more robust
 *         methods like random permutation to avoid aliasing with highly correlated vectors.
 *         This is not a bug but a documented trade-off.
 *
 *  ‚úÖ DOC: (Architectural Choice: Deterministic Rebuilds) Clarified that resetting
 *         hypervectors to their initial state during a rebuild is intentional. The system's
 *         "intuition" is deterministically re-derived by replaying the entire assertion
 *         log. This ensures the state is always a pure, auditable function of its
 *         ground-truth knowledge.
 *
 *  ‚úÖ DOC: (Architectural Limitation: Querying) Acknowledged that the current relation storage
 *         model is optimized for subject-centric queries only. Efficiently querying by object
 *         or relation (O(1)) would require building additional indices (e.g., POS, OSP) in
 *         a production-grade system.
 */

//==============================================================================
// HEADERS & PLATFORM-SPECIFIC CODE
//==============================================================================
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <time.h>
#include <stdbool.h>
#include <errno.h>

#ifdef _WIN32
#include <windows.h>
#else
#include <pthread.h>
#include <unistd.h>
#endif

#ifdef __AVX2__
#include <immintrin.h>
#endif

//==============================================================================
// 1. PUBLIC API DECLARATION & CONFIGURATION (THE "core.h" PART)
//==============================================================================

// --- Opaque Pointers ---
typedef struct CORE_HyperVector_s CORE_HyperVector;
typedef struct CORE_KnowledgeBase_s CORE_KnowledgeBase;
typedef struct CORE_Arena_s CORE_Arena;

// --- Constants & Typedefs ---
#define CORE_MAX_CONCEPT_NAME 64
#define CORE_MAX_RELATION_NAME 64
#define CORE_FILE_MAGIC 0x43524537 // "CRE7"
#define CORE_FILE_VERSION 700      // v7.0.0
#define CORE_AVX_ALIGNMENT 32

typedef enum {
    CORE_OK = 0,
    CORE_ERR_NULL_ARG,
    CORE_ERR_INVALID_CONFIG,
    CORE_ERR_MALLOC_FAILED,
    CORE_ERR_NAME_TOO_LONG,
    CORE_ERR_NOT_FOUND,
    CORE_ERR_ALREADY_EXISTS,
    CORE_ERR_FILE_IO,
    CORE_ERR_INVALID_FILE,
    CORE_ERR_VERSION_MISMATCH,
    CORE_ERR_EMPTY_LOG
} CORE_Status;

typedef struct {
    uint32_t dimensionality;
    uint32_t gravitational_constant;
    uint32_t min_gravitational_distance;
    size_t initial_buckets;
    double resize_load_factor;
    uint64_t seed;
    size_t similarity_cache_size;
} CORE_Config;

typedef struct {
    char name[CORE_MAX_CONCEPT_NAME];
    uint32_t distance;
} CORE_SearchResult;

typedef struct {
    char relation[CORE_MAX_RELATION_NAME];
    char object[CORE_MAX_CONCEPT_NAME];
    int strength;
} CORE_Relation;

typedef struct {
    const char* subject;
    const char* relation;
    const char* object;
    int strength;
} CORE_BatchAssertion;

typedef struct {
    size_t concept_count;
    size_t concept_capacity;
    size_t assertion_count;
    size_t total_relations;
    size_t node_arena_bytes;
    size_t hv_arena_bytes;
    size_t relation_arena_bytes;
    size_t sim_cache_hits;
    size_t sim_cache_misses;
} CORE_Stats;


// --- Lifecycle & Configuration ---
CORE_KnowledgeBase* core_kb_create(CORE_Config config);
void core_kb_destroy(CORE_KnowledgeBase* kb);
const char* core_status_to_string(CORE_Status status);

// --- Persistence ---
CORE_Status core_kb_save(const CORE_KnowledgeBase* kb, const char* filepath);
CORE_KnowledgeBase* core_kb_load(const char* filepath, CORE_Status* status);

// --- Knowledge Integration & Management ---
CORE_Status core_kb_assert(CORE_KnowledgeBase* kb, const char* subject, const char* relation, const char* object, int strength);
CORE_Status core_kb_assert_batch(CORE_KnowledgeBase* kb, const CORE_BatchAssertion* assertions, size_t count);
CORE_Status core_kb_unassert(CORE_KnowledgeBase* kb, const char* subject, const char* relation, const char* object);
CORE_Status core_kb_rebuild_from_log(CORE_KnowledgeBase* kb);
CORE_Status core_kb_delete_concept(CORE_KnowledgeBase* kb, const char* name);

// --- Querying, Reasoning & Introspection ---
const CORE_HyperVector* core_kb_get_vector(CORE_KnowledgeBase* kb, const char* name);
CORE_SearchResult core_kb_find_closest_bruteforce(CORE_KnowledgeBase* kb, const CORE_HyperVector* query_hv, const char* exclude_name);
CORE_Status core_kb_get_relations(CORE_KnowledgeBase* kb, const char* concept_name, CORE_Relation** out_relations, size_t* out_count);
void core_kb_free_relations(CORE_Relation* relations);
CORE_Status core_kb_get_stats(CORE_KnowledgeBase* kb, CORE_Stats* out_stats);

// --- VSA Algebraic Functions ---
CORE_HyperVector* core_hv_create_bind(const CORE_HyperVector* a, const CORE_HyperVector* b, CORE_Arena* arena);
CORE_HyperVector* core_hv_create_unbind(const CORE_HyperVector* a, const CORE_HyperVector* b, CORE_Arena* arena);
CORE_HyperVector* core_hv_create_bundle(int n_vecs, const CORE_HyperVector** hvs, CORE_Arena* arena);
uint32_t core_hv_distance(const CORE_HyperVector* a, const CORE_HyperVector* b);
uint32_t core_kb_distance(CORE_KnowledgeBase* kb, const CORE_HyperVector* a, const CORE_HyperVector* b);


//==============================================================================
// 2. PRIVATE IMPLEMENTATION DETAILS
//==============================================================================

#if defined(__GNUC__) || defined(__clang__)
#define POPCOUNT __builtin_popcountll
#else
static int fallback_popcount(uint64_t n) { int c=0; while(n>0){n&=(n-1);c++;} return c; }
#define POPCOUNT fallback_popcount
#endif

// --- Concurrency Abstraction ---
#ifdef _WIN32
typedef CRITICAL_SECTION core_mutex_t;
static void core_mutex_init(core_mutex_t* m) { InitializeCriticalSection(m); }
static void core_mutex_lock(core_mutex_t* m) { EnterCriticalSection(m); }
static void core_mutex_unlock(core_mutex_t* m) { LeaveCriticalSection(m); }
static void core_mutex_destroy(core_mutex_t* m) { DeleteCriticalSection(m); }
#else
typedef pthread_mutex_t core_mutex_t;
static void core_mutex_init(core_mutex_t* m) { pthread_mutex_init(m, NULL); }
static void core_mutex_lock(core_mutex_t* m) { pthread_mutex_lock(m); }
static void core_mutex_unlock(core_mutex_t* m) { pthread_mutex_unlock(m); }
static void core_mutex_destroy(core_mutex_t* m) { pthread_mutex_destroy(m); }
#endif

// --- Deterministic RNG (Xoroshiro128+) ---
typedef struct { uint64_t s[2]; } CORE_RNGState;
static inline uint64_t rotl(const uint64_t x, int k) { return (x << k) | (x >> (64 - k)); }
static uint64_t rng_next(CORE_RNGState* state) {
    const uint64_t s0 = state->s[0]; uint64_t s1 = state->s[1]; const uint64_t result = s0 + s1;
    s1 ^= s0; state->s[0] = rotl(s0, 24) ^ s1 ^ (s1 << 16); state->s[1] = rotl(s1, 37); return result;
}

// --- Arena Allocator ---
#define ARENA_BLOCK_SIZE (1024 * 1024)
typedef struct ArenaBlock_s { struct ArenaBlock_s* next; size_t used; uint8_t data[]; } ArenaBlock;
struct CORE_Arena_s { ArenaBlock* head; size_t total_bytes; };
typedef struct { ArenaBlock* block; size_t used; } ArenaCheckpoint;

static CORE_Arena* arena_create() { CORE_Arena* arena = calloc(1, sizeof(CORE_Arena)); return arena; }
static ArenaCheckpoint arena_checkpoint(CORE_Arena* arena) {
    if (!arena || !arena->head) return (ArenaCheckpoint){NULL, 0};
    return (ArenaCheckpoint){arena->head, arena->head->used};
}
static void arena_rollback(CORE_Arena* arena, ArenaCheckpoint checkpoint) {
    if (!arena || !checkpoint.block) return;
    while (arena->head != checkpoint.block) {
        ArenaBlock* next = arena->head->next;
        arena->total_bytes -= (sizeof(ArenaBlock) + ARENA_BLOCK_SIZE);
        free(arena->head);
        arena->head = next;
    }
    if (arena->head) {
        arena->total_bytes -= (arena->head->used - checkpoint.used);
        arena->head->used = checkpoint.used;
    }
}
static void* arena_alloc(CORE_Arena* arena, size_t size, size_t align) {
    if (!arena || size == 0) return NULL;
    if (align == 0) align = 1;

    ArenaBlock* block = arena->head;
    size_t effective_block_size = ARENA_BLOCK_SIZE;

    if (!block || (effective_block_size - block->used < size + align)) {
        size_t block_alloc_size = sizeof(ArenaBlock) + (size + align > effective_block_size ? size + align : effective_block_size);
        block = malloc(block_alloc_size); if (!block) return NULL;
        block->used = 0; block->next = arena->head; arena->head = block; arena->total_bytes += block_alloc_size;
    }
    uintptr_t current_ptr = (uintptr_t)block->data + block->used;
    uintptr_t aligned_ptr = (current_ptr + align - 1) & ~(align - 1);
    size_t padding = aligned_ptr - current_ptr;
    block->used += padding + size;
    return (void*)aligned_ptr;
}
static void arena_destroy(CORE_Arena* arena) {
    if (!arena) return; ArenaBlock* block = arena->head;
    while (block) { ArenaBlock* next = block->next; free(block); block = next; } free(arena);
}

// --- Internal Data Structures ---
struct CORE_HyperVector_s { uint32_t d; uint32_t block_count; uint64_t bits[]; };
typedef struct RelationEdge_s {
    char relation[CORE_MAX_RELATION_NAME]; char object[CORE_MAX_CONCEPT_NAME];
    int strength; struct RelationEdge_s* next;
} RelationEdge;
typedef struct ConceptNode_s {
    char name[CORE_MAX_CONCEPT_NAME];
    CORE_HyperVector* hv;
    CORE_HyperVector* hv_initial;
    struct ConceptNode_s* next;
    RelationEdge* relations_head;
    bool is_deleted;
} ConceptNode;
typedef struct {
    char subject[CORE_MAX_CONCEPT_NAME]; char relation[CORE_MAX_RELATION_NAME]; char object[CORE_MAX_CONCEPT_NAME];
    int strength; time_t timestamp;
} CORE_Assertion;

typedef struct {
    uint64_t hash_a, hash_b;
    uint32_t distance;
    uint64_t last_used;
} CORE_SimCacheEntry;
typedef struct {
    CORE_SimCacheEntry* entries;
    size_t size;
    uint64_t tick;
    size_t hits;
    size_t misses;
    core_mutex_t lock;
} CORE_SimilarityCache;

struct CORE_KnowledgeBase_s {
    CORE_Config config; CORE_RNGState rng; size_t bucket_count; size_t concept_count;
    ConceptNode** buckets; core_mutex_t* bucket_locks; 
    core_mutex_t resize_lock;
    core_mutex_t assertion_log_lock;
    core_mutex_t rng_lock;
    CORE_Arena* node_arena; CORE_Arena* hv_arena; CORE_Arena* relation_arena;
    CORE_Assertion* assertion_log; size_t assertion_count; size_t assertion_capacity;
    CORE_SimilarityCache* sim_cache;
};

// --- Persistence File Header ---
typedef struct {
    uint32_t magic;
    uint32_t version;
    CORE_Config config;
    size_t assertion_count;
} CORE_FileHeader;


// --- Forward Declarations for Internal Helpers ---
static ConceptNode* find_concept_node_internal(CORE_KnowledgeBase* kb, const char* name, bool allow_deleted);
static CORE_Status kb_resize(CORE_KnowledgeBase* kb);


// --- Internal Helper Functions ---
static CORE_HyperVector* hv_alloc_internal(uint32_t d, CORE_Arena* arena) {
    size_t block_count = (d + 63) / 64;
    size_t alignment = 16;
    #ifdef __AVX2__
    alignment = CORE_AVX_ALIGNMENT;
    #endif
    CORE_HyperVector* hv = arena_alloc(arena, sizeof(CORE_HyperVector) + sizeof(uint64_t) * block_count, alignment);
    if (!hv) return NULL; hv->d = d; hv->block_count = block_count;
    memset(hv->bits, 0, sizeof(uint64_t) * block_count); return hv;
}

static uint64_t rng_next_locked(CORE_KnowledgeBase* kb) {
    core_mutex_lock(&kb->rng_lock);
    uint64_t val = rng_next(&kb->rng);
    core_mutex_unlock(&kb->rng_lock);
    return val;
}

static CORE_HyperVector* hv_create_random_internal(CORE_KnowledgeBase* kb) {
    CORE_HyperVector* hv = hv_alloc_internal(kb->config.dimensionality, kb->hv_arena);
    if (!hv) return NULL;
    for (uint32_t i = 0; i < hv->block_count; ++i) { hv->bits[i] = rng_next_locked(kb); }
    
    uint32_t remainder_bits = kb->config.dimensionality % 64;
    if (remainder_bits > 0) {
        uint64_t mask = (1ULL << remainder_bits) - 1;
        hv->bits[hv->block_count - 1] &= mask;
    }
    return hv;
}

static unsigned long hash_string(const char* str) {
    unsigned long hash = 5381; int c; while ((c = *str++)) { hash = ((hash << 5) + hash) + c; } return hash;
}

static void hv_apply_gravity_internal(CORE_HyperVector* target, const CORE_HyperVector* influence, CORE_KnowledgeBase* kb, uint32_t* scratch_buffer) {
    // FIX (Semantic Collapse): Prevent concepts from getting too close and merging.
    uint32_t current_dist = core_hv_distance(target, influence);
    if (current_dist <= kb->config.min_gravitational_distance) {
        return;
    }

    uint32_t* differing_indices = scratch_buffer;
    uint32_t diff_count = 0;
    for (uint32_t i = 0; i < target->block_count; ++i) {
        uint64_t xor_block = target->bits[i] ^ influence->bits[i]; if (xor_block == 0) continue;
        for (int j = 0; j < 64; ++j) {
            if ((xor_block >> j) & 1) {
                uint32_t bit_index = i * 64 + j;
                if (bit_index < target->d) {
                    differing_indices[diff_count++] = bit_index;
                }
            }
        }
    }
    if (diff_count > 0) {
        uint32_t gravity = kb->config.gravitational_constant;
        for (uint32_t i = 0; i < gravity && diff_count > 0; ++i) {
            uint64_t rand_val = rng_next_locked(kb);
            uint32_t rand_idx = rand_val % diff_count;
            uint32_t bit_to_flip = differing_indices[rand_idx];
            target->bits[bit_to_flip / 64] ^= (1ULL << (bit_to_flip % 64));
            differing_indices[rand_idx] = differing_indices[diff_count - 1];
            diff_count--;
        }
    }
}

static ConceptNode* get_or_create_concept_node(CORE_KnowledgeBase* kb, const char* name) {
    core_mutex_lock(&kb->resize_lock);
    if ((double)(kb->concept_count + 1) / kb->bucket_count > kb->config.resize_load_factor) {
        if (kb_resize(kb) != CORE_OK) {
            core_mutex_unlock(&kb->resize_lock);
            return NULL;
        }
    }
    
    size_t index = hash_string(name) % kb->bucket_count;
    core_mutex_lock(&kb->bucket_locks[index]);

    for (ConceptNode* current = kb->buckets[index]; current; current = current->next) {
        if (strcmp(current->name, name) == 0) {
            if (current->is_deleted) {
                current->is_deleted = false;
                kb->concept_count++; // FIX (Concurrency): Protected by resize_lock.
            }
            core_mutex_unlock(&kb->resize_lock);
            core_mutex_unlock(&kb->bucket_locks[index]);
            return current;
        }
    }

    ConceptNode* new_node = arena_alloc(kb->node_arena, sizeof(ConceptNode), 8);
    if (!new_node) { core_mutex_unlock(&kb->resize_lock); core_mutex_unlock(&kb->bucket_locks[index]); return NULL; }
    memset(new_node, 0, sizeof(ConceptNode));
    strncpy(new_node->name, name, CORE_MAX_CONCEPT_NAME - 1);

    new_node->hv_initial = hv_create_random_internal(kb);
    new_node->hv = hv_alloc_internal(kb->config.dimensionality, kb->hv_arena);
    if (!new_node->hv_initial || !new_node->hv) { core_mutex_unlock(&kb->resize_lock); core_mutex_unlock(&kb->bucket_locks[index]); return NULL; }
    memcpy(new_node->hv->bits, new_node->hv_initial->bits, sizeof(uint64_t) * new_node->hv->block_count);

    new_node->next = kb->buckets[index];
    kb->buckets[index] = new_node;
    kb->concept_count++; // FIX (Concurrency): Protected by resize_lock.
    
    core_mutex_unlock(&kb->resize_lock);
    core_mutex_unlock(&kb->bucket_locks[index]);
    return new_node;
}

static CORE_Status core_kb_apply_assertion_no_log(CORE_KnowledgeBase* kb, const char* subject_name, const char* relation_name, const char* object_name, int strength) {
    ConceptNode* subj_node = get_or_create_concept_node(kb, subject_name);
    ConceptNode* rel_node = get_or_create_concept_node(kb, relation_name);
    ConceptNode* obj_node = get_or_create_concept_node(kb, object_name);
    if (!subj_node || !rel_node || !obj_node) return CORE_ERR_MALLOC_FAILED;

    CORE_Arena* temp_arena = arena_create();
    if (!temp_arena) return CORE_ERR_MALLOC_FAILED;

    CORE_HyperVector* influence = core_hv_create_bind(rel_node->hv, obj_node->hv, temp_arena);
    uint32_t* gravity_scratch = malloc(sizeof(uint32_t) * kb->config.dimensionality);

    if (!influence || !gravity_scratch) { 
        free(gravity_scratch);
        arena_destroy(temp_arena); 
        return CORE_ERR_MALLOC_FAILED; 
    }

    core_mutex_lock(&kb->resize_lock);
    size_t subj_index = hash_string(subject_name) % kb->bucket_count;
    core_mutex_lock(&kb->bucket_locks[subj_index]);
    core_mutex_unlock(&kb->resize_lock);
    
    ConceptNode* locked_subj_node = NULL;
    for(ConceptNode* n = kb->buckets[subj_index]; n != NULL; n = n->next) {
        if(strcmp(n->name, subject_name) == 0) { locked_subj_node = n; break; }
    }
    
    if(locked_subj_node) {
    // 1. Apply the original structural gravity (S is pulled towards R ‚®Ç O)
    for (int i = 0; i < strength; ++i) {
        hv_apply_gravity_internal(locked_subj_node->hv, influence, kb, gravity_scratch);
    }

    // 2. üî• THE FIX: Add a direct, symmetric pull for hierarchical relationships (`is_a`)
    if (strcmp(relation_name, "is_a") == 0 || strcmp(relation_name, "is_an") == 0) {
        // We already have the subject's bucket locked. Now we need to find and lock the object's.
        size_t obj_index = hash_string(object_name) % kb->bucket_count;

        // To prevent deadlock, always lock the bucket with the lower index first.
        if (obj_index == subj_index) {
            // Already locked, do nothing special.
        } else if (obj_index < subj_index) {
            core_mutex_unlock(&kb->bucket_locks[subj_index]); // Unlock higher index
            core_mutex_lock(&kb->bucket_locks[obj_index]);   // Lock lower index
            core_mutex_lock(&kb->bucket_locks[subj_index]);   // Re-lock higher index
        } else { // obj_index > subj_index
            core_mutex_lock(&kb->bucket_locks[obj_index]);
        }
        
        // Now that both buckets are safely locked, find the object node
        ConceptNode* locked_obj_node = NULL;
        for(ConceptNode* n = kb->buckets[obj_index]; n != NULL; n = n->next) {
            if(strcmp(n->name, object_name) == 0) { locked_obj_node = n; break; }
        }

        if (locked_obj_node) {
            // Pull the subject (instance) towards the object (class)
            // And pull the object (class) towards the subject (instance) to strengthen the cluster
            int direct_pull_strength = strength / 2 + 1; // Make it strong
            for (int i = 0; i < direct_pull_strength; i++) {
                hv_apply_gravity_internal(locked_subj_node->hv, locked_obj_node->hv, kb, gravity_scratch);
                hv_apply_gravity_internal(locked_obj_node->hv, locked_subj_node->hv, kb, gravity_scratch);
            }
        }

        // Unlock the object's bucket if we locked it
        if (obj_index != subj_index) {
            core_mutex_unlock(&kb->bucket_locks[obj_index]);
        }
    }

    // 3. Update the explicit relation graph (this part is unchanged)
    bool edge_found = false;
    for (RelationEdge* edge = locked_subj_node->relations_head; edge != NULL; edge = edge->next) {
        if (strcmp(edge->relation, relation_name) == 0 && strcmp(edge->object, object_name) == 0) {
            edge->strength += strength; edge_found = true; break;
        }
    }
    if (!edge_found) {
        RelationEdge* new_edge = arena_alloc(kb->relation_arena, sizeof(RelationEdge), 8);
        if (new_edge) {
            strncpy(new_edge->relation, relation_name, CORE_MAX_RELATION_NAME - 1);
            strncpy(new_edge->object, object_name, CORE_MAX_CONCEPT_NAME - 1);
            new_edge->strength = strength; new_edge->next = locked_subj_node->relations_head;
            locked_subj_node->relations_head = new_edge;
        }
    }
}

    core_mutex_unlock(&kb->bucket_locks[subj_index]);
    free(gravity_scratch);
    arena_destroy(temp_arena);
    return CORE_OK;
}

//==============================================================================
// 3. PUBLIC API IMPLEMENTATION
//==============================================================================
const char* core_status_to_string(CORE_Status status) {
    switch (status) {
        case CORE_OK: return "Operation successful";
        case CORE_ERR_NULL_ARG: return "Null argument provided";
        case CORE_ERR_INVALID_CONFIG: return "Invalid configuration";
        case CORE_ERR_MALLOC_FAILED: return "Memory allocation failed";
        case CORE_ERR_NAME_TOO_LONG: return "Concept name exceeds maximum length";
        case CORE_ERR_NOT_FOUND: return "Concept not found";
        case CORE_ERR_ALREADY_EXISTS: return "Concept already exists";
        case CORE_ERR_FILE_IO: return "File I/O error";
        case CORE_ERR_INVALID_FILE: return "Invalid or corrupted C.O.R.E. file";
        case CORE_ERR_VERSION_MISMATCH: return "File version mismatch";
        case CORE_ERR_EMPTY_LOG: return "Assertion log is empty, cannot rebuild";
        default: return "Unknown error";
    }
}

CORE_KnowledgeBase* core_kb_create(CORE_Config config) {
    if (config.dimensionality == 0 || config.initial_buckets == 0) return NULL;
    CORE_KnowledgeBase* kb = calloc(1, sizeof(CORE_KnowledgeBase)); if (!kb) return NULL;

    kb->config = config;
    if (kb->config.seed == 0) kb->config.seed = time(NULL);
    if (kb->config.min_gravitational_distance == 0) kb->config.min_gravitational_distance = 5;
    kb->rng.s[0] = kb->config.seed; kb->rng.s[1] = kb->config.seed ^ 0xdeadbeefcafebabe;

    kb->node_arena = arena_create(); kb->hv_arena = arena_create(); kb->relation_arena = arena_create();
    kb->bucket_count = config.initial_buckets;
    kb->buckets = calloc(kb->bucket_count, sizeof(ConceptNode*));
    kb->bucket_locks = malloc(sizeof(core_mutex_t) * kb->bucket_count);

    if (config.similarity_cache_size > 0) {
        kb->sim_cache = calloc(1, sizeof(CORE_SimilarityCache));
        if(kb->sim_cache) {
            kb->sim_cache->size = config.similarity_cache_size;
            kb->sim_cache->entries = calloc(kb->sim_cache->size, sizeof(CORE_SimCacheEntry));
            if(!kb->sim_cache->entries) { free(kb->sim_cache); kb->sim_cache = NULL; }
            else { core_mutex_init(&kb->sim_cache->lock); }
        }
    }

    if (!kb->node_arena || !kb->hv_arena || !kb->relation_arena || !kb->buckets || !kb->bucket_locks) {
        core_kb_destroy(kb); return NULL;
    }
    core_mutex_init(&kb->resize_lock);
    core_mutex_init(&kb->assertion_log_lock);
    core_mutex_init(&kb->rng_lock);
    for (size_t i = 0; i < kb->bucket_count; ++i) { core_mutex_init(&kb->bucket_locks[i]); }
    return kb;
}

void core_kb_destroy(CORE_KnowledgeBase* kb) {
    if (!kb) return;
    arena_destroy(kb->node_arena); arena_destroy(kb->hv_arena); arena_destroy(kb->relation_arena);
    if(kb->bucket_locks) {
        for (size_t i = 0; i < kb->bucket_count; ++i) core_mutex_destroy(&kb->bucket_locks[i]);
        free(kb->bucket_locks);
    }
    if (kb->sim_cache) {
        core_mutex_destroy(&kb->sim_cache->lock);
        free(kb->sim_cache->entries);
        free(kb->sim_cache);
    }
    core_mutex_destroy(&kb->resize_lock);
    core_mutex_destroy(&kb->assertion_log_lock);
    core_mutex_destroy(&kb->rng_lock);
    free(kb->buckets); free(kb->assertion_log);
    free(kb);
}

CORE_Status core_kb_save(const CORE_KnowledgeBase* kb, const char* filepath) {
    if (!kb || !filepath) return CORE_ERR_NULL_ARG;

    FILE* fp = fopen(filepath, "wb");
    if (!fp) return CORE_ERR_FILE_IO;

    core_mutex_lock((core_mutex_t*)&kb->assertion_log_lock);

    CORE_FileHeader header = {
        .magic = CORE_FILE_MAGIC,
        .version = CORE_FILE_VERSION,
        .config = kb->config,
        .assertion_count = kb->assertion_count
    };

    CORE_Status status = CORE_OK;
    if (fwrite(&header, sizeof(CORE_FileHeader), 1, fp) != 1) {
        status = CORE_ERR_FILE_IO;
        goto cleanup;
    }

    if (header.assertion_count > 0) {
        if (fwrite(kb->assertion_log, sizeof(CORE_Assertion), header.assertion_count, fp) != header.assertion_count) {
            status = CORE_ERR_FILE_IO;
            goto cleanup;
        }
    }

cleanup:
    core_mutex_unlock((core_mutex_t*)&kb->assertion_log_lock);
    fclose(fp);
    return status;
}

CORE_KnowledgeBase* core_kb_load(const char* filepath, CORE_Status* out_status) {
    if (!filepath || !out_status) {
        if (out_status) *out_status = CORE_ERR_NULL_ARG;
        return NULL;
    }

    FILE* fp = fopen(filepath, "rb");
    if (!fp) {
        *out_status = CORE_ERR_FILE_IO;
        return NULL;
    }

    CORE_FileHeader header;
    if (fread(&header, sizeof(CORE_FileHeader), 1, fp) != 1) {
        *out_status = CORE_ERR_INVALID_FILE;
        fclose(fp);
        return NULL;
    }

    if (header.magic != CORE_FILE_MAGIC) {
        *out_status = CORE_ERR_INVALID_FILE;
        fclose(fp);
        return NULL;
    }
    if (header.version > CORE_FILE_VERSION) {
        *out_status = CORE_ERR_VERSION_MISMATCH;
        fclose(fp);
        return NULL;
    }

    CORE_KnowledgeBase* kb = core_kb_create(header.config);
    if (!kb) {
        *out_status = CORE_ERR_MALLOC_FAILED;
        fclose(fp);
        return NULL;
    }

    if (header.assertion_count > 0) {
        kb->assertion_log = malloc(sizeof(CORE_Assertion) * header.assertion_count);
        if (!kb->assertion_log) {
            *out_status = CORE_ERR_MALLOC_FAILED;
            fclose(fp);
            core_kb_destroy(kb);
            return NULL;
        }
        kb->assertion_count = header.assertion_count;
        kb->assertion_capacity = header.assertion_count;

        if (fread(kb->assertion_log, sizeof(CORE_Assertion), header.assertion_count, fp) != header.assertion_count) {
            *out_status = CORE_ERR_INVALID_FILE; // Likely truncated
            fclose(fp);
            core_kb_destroy(kb);
            return NULL;
        }
    }
    fclose(fp);

    *out_status = core_kb_rebuild_from_log(kb);
    if (*out_status != CORE_OK) {
        core_kb_destroy(kb);
        return NULL;
    }

    return kb;
}

CORE_Status core_kb_assert(CORE_KnowledgeBase* kb, const char* subject_name, const char* relation_name, const char* object_name, int strength) {
    if (!kb || !subject_name || !relation_name || !object_name) return CORE_ERR_NULL_ARG;
    if (strlen(subject_name) >= CORE_MAX_CONCEPT_NAME || strlen(relation_name) >= CORE_MAX_RELATION_NAME || strlen(object_name) >= CORE_MAX_CONCEPT_NAME) return CORE_ERR_NAME_TOO_LONG;

    CORE_Status status = core_kb_apply_assertion_no_log(kb, subject_name, relation_name, object_name, strength);
    if (status != CORE_OK) {
        return status;
    }

    core_mutex_lock(&kb->assertion_log_lock);
    if(kb->assertion_count >= kb->assertion_capacity) {
        size_t new_cap = kb->assertion_capacity == 0 ? 128 : kb->assertion_capacity * 2;
        CORE_Assertion* new_log = realloc(kb->assertion_log, sizeof(CORE_Assertion) * new_cap);
        if(!new_log) {
            core_mutex_unlock(&kb->assertion_log_lock);
            return CORE_ERR_MALLOC_FAILED;
        }
        kb->assertion_log = new_log; kb->assertion_capacity = new_cap;
    }
    CORE_Assertion* log = &kb->assertion_log[kb->assertion_count++];
    strncpy(log->subject, subject_name, CORE_MAX_CONCEPT_NAME - 1); log->subject[CORE_MAX_CONCEPT_NAME-1] = '\0';
    strncpy(log->relation, relation_name, CORE_MAX_RELATION_NAME - 1); log->relation[CORE_MAX_RELATION_NAME-1] = '\0';
    strncpy(log->object, object_name, CORE_MAX_CONCEPT_NAME - 1); log->object[CORE_MAX_CONCEPT_NAME-1] = '\0';
    log->strength = strength; log->timestamp = time(NULL);
    core_mutex_unlock(&kb->assertion_log_lock);

    return CORE_OK;
}

CORE_Status core_kb_assert_batch(CORE_KnowledgeBase* kb, const CORE_BatchAssertion* assertions, size_t count) {
    if (!kb || !assertions) return CORE_ERR_NULL_ARG;
    for (size_t i = 0; i < count; ++i) {
        CORE_Status s = core_kb_assert(kb, assertions[i].subject, assertions[i].relation, assertions[i].object, assertions[i].strength);
        if (s != CORE_OK) return s;
    }
    return CORE_OK;
}

CORE_Status core_kb_unassert(CORE_KnowledgeBase* kb, const char* subject, const char* relation, const char* object) {
    if (!kb || !subject || !relation || !object) return CORE_ERR_NULL_ARG;
    
    core_mutex_lock(&kb->assertion_log_lock);
    size_t new_log_count = 0;
    bool found = false;
    for (size_t i = 0; i < kb->assertion_count; ++i) {
        if (strcmp(kb->assertion_log[i].subject, subject) == 0 &&
            strcmp(kb->assertion_log[i].relation, relation) == 0 &&
            strcmp(kb->assertion_log[i].object, object) == 0) {
            found = true;
        } else {
            if (i != new_log_count) kb->assertion_log[new_log_count] = kb->assertion_log[i];
            new_log_count++;
        }
    }
    if (!found) { core_mutex_unlock(&kb->assertion_log_lock); return CORE_ERR_NOT_FOUND; }
    kb->assertion_count = new_log_count;
    core_mutex_unlock(&kb->assertion_log_lock);
    
    // API Contract: The user must call core_kb_rebuild_from_log() to apply this change.
    return CORE_OK;
}

static int compare_assertions(const void* a, const void* b) {
    const CORE_Assertion* ass_a = (const CORE_Assertion*)a;
    const CORE_Assertion* ass_b = (const CORE_Assertion*)b;
    int cmp = strcmp(ass_a->subject, ass_b->subject);
    if (cmp != 0) return cmp;
    cmp = strcmp(ass_a->relation, ass_b->relation);
    if (cmp != 0) return cmp;
    cmp = strcmp(ass_a->object, ass_b->object);
    if (cmp != 0) return cmp;
    return (ass_a->timestamp < ass_b->timestamp) ? -1 : (ass_a->timestamp > ass_b->timestamp);
}

CORE_Status core_kb_rebuild_from_log(CORE_KnowledgeBase* kb) {
    if (!kb) return CORE_ERR_NULL_ARG;

    core_mutex_lock(&kb->resize_lock);
    for(size_t i=0; i<kb->bucket_count; ++i) core_mutex_lock(&kb->bucket_locks[i]);

    kb->rng.s[0] = kb->config.seed;
    kb->rng.s[1] = kb->config.seed ^ 0xdeadbeefcafebabe;
    
    arena_destroy(kb->relation_arena);
    kb->relation_arena = arena_create();
    if (!kb->relation_arena) { 
        for(size_t i=0; i<kb->bucket_count; ++i) core_mutex_unlock(&kb->bucket_locks[i]);
        core_mutex_unlock(&kb->resize_lock);
        return CORE_ERR_MALLOC_FAILED; 
    }

    for (size_t i = 0; i < kb->bucket_count; ++i) {
        for (ConceptNode* node = kb->buckets[i]; node != NULL; node = node->next) {
            node->relations_head = NULL;
            // DOC (Architectural Choice): Reset to initial state for deterministic replay.
            memcpy(node->hv->bits, node->hv_initial->bits, sizeof(uint64_t) * node->hv->block_count);
        }
    }
    
    for(size_t i=0; i<kb->bucket_count; ++i) core_mutex_unlock(&kb->bucket_locks[i]);
    core_mutex_unlock(&kb->resize_lock);

    if (kb->sim_cache) {
        core_mutex_lock(&kb->sim_cache->lock);
        memset(kb->sim_cache->entries, 0, sizeof(CORE_SimCacheEntry) * kb->sim_cache->size);
        kb->sim_cache->hits = 0; kb->sim_cache->misses = 0; kb->sim_cache->tick = 0;
        core_mutex_unlock(&kb->sim_cache->lock);
    }
    
    core_mutex_lock(&kb->assertion_log_lock);
    if (kb->assertion_count == 0) {
        core_mutex_unlock(&kb->assertion_log_lock);
        return CORE_OK;
    }

    qsort(kb->assertion_log, kb->assertion_count, sizeof(CORE_Assertion), compare_assertions);

    for (size_t i = 0; i < kb->assertion_count; ++i) {
        CORE_Assertion* log = &kb->assertion_log[i];
        core_kb_apply_assertion_no_log(kb, log->subject, log->relation, log->object, log->strength);
    }
    core_mutex_unlock(&kb->assertion_log_lock);

    return CORE_OK;
}

CORE_Status core_kb_delete_concept(CORE_KnowledgeBase* kb, const char* name) {
    if (!kb || !name) return CORE_ERR_NULL_ARG;
    
    core_mutex_lock(&kb->resize_lock);
    size_t index = hash_string(name) % kb->bucket_count;
    core_mutex_lock(&kb->bucket_locks[index]);

    ConceptNode* node_to_delete = NULL;
    for (ConceptNode* n = kb->buckets[index]; n; n=n->next) {
        if (strcmp(n->name, name) == 0) { node_to_delete = n; break; }
    }
    
    if (!node_to_delete || node_to_delete->is_deleted) {
        core_mutex_unlock(&kb->bucket_locks[index]);
        core_mutex_unlock(&kb->resize_lock);
        return CORE_ERR_NOT_FOUND;
    }
    
    node_to_delete->is_deleted = true;
    kb->concept_count--; // FIX (Concurrency): Protected by resize_lock.

    core_mutex_unlock(&kb->bucket_locks[index]);
    core_mutex_unlock(&kb->resize_lock);

    core_mutex_lock(&kb->assertion_log_lock);
    size_t new_log_count = 0;
    for (size_t i = 0; i < kb->assertion_count; ++i) {
        CORE_Assertion* log = &kb->assertion_log[i];
        if (strcmp(log->subject, name) != 0 && strcmp(log->object, name) != 0 && strcmp(log->relation, name) != 0) {
            if (i != new_log_count) kb->assertion_log[new_log_count] = kb->assertion_log[i];
            new_log_count++;
        }
    }
    kb->assertion_count = new_log_count;
    core_mutex_unlock(&kb->assertion_log_lock);
    
    // API Contract: The user must call core_kb_rebuild_from_log() to apply this change.
    return CORE_OK;
}

static ConceptNode* find_concept_node_internal(CORE_KnowledgeBase* kb, const char* name, bool allow_deleted) {
    if (!kb || !name) return NULL;
    core_mutex_lock(&kb->resize_lock);
    size_t index = hash_string(name) % kb->bucket_count;
    core_mutex_lock(&kb->bucket_locks[index]);
    core_mutex_unlock(&kb->resize_lock);

    ConceptNode* found_node = NULL;
    for (ConceptNode* current = kb->buckets[index]; current; current = current->next) {
        if (strcmp(current->name, name) == 0) {
            if (allow_deleted || !current->is_deleted) {
                 found_node = current;
            }
            break;
        }
    }
    core_mutex_unlock(&kb->bucket_locks[index]);
    return found_node;
}

const CORE_HyperVector* core_kb_get_vector(CORE_KnowledgeBase* kb, const char* name) {
    ConceptNode* node = find_concept_node_internal(kb, name, false);
    return node ? node->hv : NULL;
}

CORE_SearchResult core_kb_find_closest_bruteforce(CORE_KnowledgeBase* kb, const CORE_HyperVector* query_hv, const char* exclude_name) {
    CORE_SearchResult result = { "", kb->config.dimensionality + 1 };
    if (!kb || !query_hv) return result;
    
    core_mutex_lock(&kb->resize_lock);
    size_t current_bucket_count = kb->bucket_count;
    
    for (size_t i = 0; i < current_bucket_count; ++i) {
        core_mutex_lock(&kb->bucket_locks[i]);
        for (ConceptNode* node = kb->buckets[i]; node != NULL; node = node->next) {
            if (node->is_deleted || (exclude_name && strcmp(node->name, exclude_name) == 0)) continue;
            uint32_t dist = core_kb_distance(kb, query_hv, node->hv);
            if (dist < result.distance) {
                result.distance = dist; strncpy(result.name, node->name, CORE_MAX_CONCEPT_NAME-1); result.name[CORE_MAX_CONCEPT_NAME - 1] = '\0';
            }
        }
        core_mutex_unlock(&kb->bucket_locks[i]);
    }
    core_mutex_unlock(&kb->resize_lock);
    return result;
}

CORE_Status core_kb_get_relations(CORE_KnowledgeBase* kb, const char* concept_name, CORE_Relation** out_relations, size_t* out_count) {
    if (!kb || !concept_name || !out_relations || !out_count) return CORE_ERR_NULL_ARG;
    *out_relations = NULL; *out_count = 0;
    
    core_mutex_lock(&kb->resize_lock);
    size_t index = hash_string(concept_name) % kb->bucket_count;
    core_mutex_lock(&kb->bucket_locks[index]);
    core_mutex_unlock(&kb->resize_lock);
    
    ConceptNode* node = NULL;
    for (ConceptNode* n = kb->buckets[index]; n != NULL; n = n->next) {
        if (strcmp(n->name, concept_name) == 0 && !n->is_deleted) {
            node = n;
            break;
        }
    }

    if (!node) {
        core_mutex_unlock(&kb->bucket_locks[index]);
        return CORE_ERR_NOT_FOUND;
    }
    
    size_t count = 0;
    for (RelationEdge* e = node->relations_head; e; e = e->next) if (e->strength > 0) count++;
    
    if (count > 0) {
        CORE_Relation* relations = malloc(sizeof(CORE_Relation) * count);
        if (!relations) {
            core_mutex_unlock(&kb->bucket_locks[index]);
            return CORE_ERR_MALLOC_FAILED;
        }
        size_t i = 0;
        for (RelationEdge* e = node->relations_head; e; e = e->next) {
            if (e->strength > 0) {
                strncpy(relations[i].relation, e->relation, CORE_MAX_RELATION_NAME-1);
                relations[i].relation[CORE_MAX_RELATION_NAME-1] = '\0';
                strncpy(relations[i].object, e->object, CORE_MAX_CONCEPT_NAME-1);
                relations[i].object[CORE_MAX_CONCEPT_NAME-1] = '\0';
                relations[i].strength = e->strength; i++;
            }
        }
        *out_relations = relations; *out_count = count;
    }

    core_mutex_unlock(&kb->bucket_locks[index]);
    return CORE_OK;
}
void core_kb_free_relations(CORE_Relation* relations) { free(relations); }

CORE_Status core_kb_get_stats(CORE_KnowledgeBase* kb, CORE_Stats* out_stats) {
    if (!kb || !out_stats) return CORE_ERR_NULL_ARG;
    memset(out_stats, 0, sizeof(CORE_Stats));

    core_mutex_lock(&kb->resize_lock);
    size_t current_bucket_count = kb->bucket_count;
    
    out_stats->concept_count = kb->concept_count;
    out_stats->concept_capacity = current_bucket_count;
    out_stats->assertion_count = kb->assertion_count;
    out_stats->node_arena_bytes = kb->node_arena->total_bytes;
    out_stats->hv_arena_bytes = kb->hv_arena->total_bytes;
    out_stats->relation_arena_bytes = kb->relation_arena->total_bytes;
    if (kb->sim_cache) {
        out_stats->sim_cache_hits = kb->sim_cache->hits;
        out_stats->sim_cache_misses = kb->sim_cache->misses;
    }

    for (size_t i = 0; i < current_bucket_count; ++i) {
        core_mutex_lock(&kb->bucket_locks[i]);
        for (ConceptNode* node = kb->buckets[i]; node != NULL; node = node->next) {
            if(node->is_deleted) continue;
            for (RelationEdge* e = node->relations_head; e; e = e->next) {
                if(e->strength > 0) out_stats->total_relations++;
            }
        }
        core_mutex_unlock(&kb->bucket_locks[i]);
    }
    core_mutex_unlock(&kb->resize_lock);
    return CORE_OK;
}

uint32_t core_hv_distance(const CORE_HyperVector* a, const CORE_HyperVector* b) {
    if (!a || !b || a->d != b->d) return (uint32_t)-1;
    uint32_t distance = 0;
    uint32_t i = 0;
#ifdef __AVX2__
    uint32_t avx_blocks_end = (a->block_count / 4) * 4;
    for (i = 0; i < avx_blocks_end; i += 4) {
        __m256i vec_a = _mm256_loadu_si256((__m256i const*)&a->bits[i]);
        __m256i vec_b = _mm256_loadu_si256((__m256i const*)&b->bits[i]);
        __m256i xored = _mm256_xor_si256(vec_a, vec_b);
        uint64_t temp[4];
        _mm256_storeu_si256((__m256i*)temp, xored);
        distance += POPCOUNT(temp[0]) + POPCOUNT(temp[1]) + POPCOUNT(temp[2]) + POPCOUNT(temp[3]);
    }
#endif
    for (; i < a->block_count; ++i) {
        distance += POPCOUNT(a->bits[i] ^ b->bits[i]);
    }
    return distance;
}

static uint64_t core_hv_hash(const CORE_HyperVector* hv) {
    if (!hv) return 0;
    uint64_t hash = 14695981039346656037ULL; // FNV-1a
    const uint8_t* data = (const uint8_t*)hv->bits;
    size_t len = hv->block_count * sizeof(uint64_t); 
    for (size_t i = 0; i < len; i++) {
        hash ^= data[i];
        hash *= 1099511628211ULL;
    }
    return hash;
}

uint32_t core_kb_distance(CORE_KnowledgeBase* kb, const CORE_HyperVector* a, const CORE_HyperVector* b) {
    if (!kb || !kb->sim_cache) return core_hv_distance(a, b);

    CORE_SimilarityCache* cache = kb->sim_cache;
    uint64_t hash_a = core_hv_hash(a);
    uint64_t hash_b = core_hv_hash(b);
    if (hash_a > hash_b) { uint64_t tmp = hash_a; hash_a = hash_b; hash_b = tmp; }

    core_mutex_lock(&cache->lock);
    for (size_t i = 0; i < cache->size; ++i) {
        if (cache->entries[i].hash_a == hash_a && cache->entries[i].hash_b == hash_b) {
            cache->entries[i].last_used = ++cache->tick;
            cache->hits++;
            uint32_t dist = cache->entries[i].distance;
            core_mutex_unlock(&cache->lock);
            return dist;
        }
    }
    
    uint32_t dist = core_hv_distance(a, b);

    size_t evict_idx = 0;
    uint64_t min_tick = UINT64_MAX;
    for (size_t i = 0; i < cache->size; ++i) {
        if (cache->entries[i].last_used < min_tick) {
            min_tick = cache->entries[i].last_used;
            evict_idx = i;
        }
    }
    cache->misses++;
    cache->entries[evict_idx].hash_a = hash_a;
    cache->entries[evict_idx].hash_b = hash_b;
    cache->entries[evict_idx].distance = dist;
    cache->entries[evict_idx].last_used = ++cache->tick;
    core_mutex_unlock(&cache->lock);
    return dist;
}

CORE_HyperVector* core_hv_create_bind(const CORE_HyperVector* a, const CORE_HyperVector* b, CORE_Arena* arena) {
    // DOC (Architectural Choice): Using simple XOR for binding.
    if (!a || !b || a->d != b->d || !arena) return NULL;
    CORE_HyperVector* result = hv_alloc_internal(a->d, arena); if (!result) return NULL;
    for (uint32_t i = 0; i < a->block_count; ++i) result->bits[i] = a->bits[i] ^ b->bits[i]; return result;
}
CORE_HyperVector* core_hv_create_unbind(const CORE_HyperVector* a, const CORE_HyperVector* b, CORE_Arena* arena) { return core_hv_create_bind(a, b, arena); }

CORE_HyperVector* core_hv_create_bundle(int n_vecs, const CORE_HyperVector** hvs, CORE_Arena* arena) {
    if (n_vecs == 0 || !hvs || !arena) return NULL;
    uint32_t d = hvs[0]->d;
    
    ArenaCheckpoint checkpoint = arena_checkpoint(arena);
    CORE_HyperVector* result = hv_alloc_internal(d, arena);
    int* sums = malloc(sizeof(int) * d);
    if (!result || !sums) {
        free(sums);
        arena_rollback(arena, checkpoint);
        return NULL;
    }

    memset(sums, 0, sizeof(int) * d);
    for (int i = 0; i < n_vecs; ++i) {
        for (uint32_t j = 0; j < hvs[i]->block_count; ++j) {
            for (int k = 0; k < 64; ++k) {
                uint32_t index = j * 64 + k;
                if (index >= d) continue;
                if ((hvs[i]->bits[j] >> k) & 1) sums[index]++; else sums[index]--;
            }
        }
    }
    
    for (uint32_t j = 0; j < d; ++j) {
        bool bit = false;
        if (sums[j] > 0) {
            bit = true;
        } else if (sums[j] == 0) {
            uint32_t hash = j; // Simple deterministic tie-breaker
            hash = ((hash >> 16) ^ hash) * 0x45d9f3b; hash = ((hash >> 16) ^ hash) * 0x45d9f3b; hash = (hash >> 16) ^ hash;
            if (hash % 2) bit = true;
        }
        if (bit) result->bits[j / 64] |= (1ULL << (j % 64));
    }
    free(sums); return result;
}

static CORE_Status kb_resize(CORE_KnowledgeBase* kb) {
    // This lock is already held by the caller (get_or_create_concept_node)
    size_t old_bucket_count = kb->bucket_count;
    ConceptNode** old_buckets = kb->buckets;
    core_mutex_t* old_locks = kb->bucket_locks;

    // FIX (Concurrency): Acquire all old locks for a "stop-the-world" rehash.
    for(size_t i = 0; i < old_bucket_count; ++i) core_mutex_lock(&old_locks[i]);

    size_t new_bucket_count = old_bucket_count * 2;
    ConceptNode** new_buckets = calloc(new_bucket_count, sizeof(ConceptNode*));
    core_mutex_t* new_locks = malloc(sizeof(core_mutex_t) * new_bucket_count);

    if (!new_buckets || !new_locks) {
        free(new_buckets); free(new_locks);
        for(size_t i = 0; i < old_bucket_count; ++i) core_mutex_unlock(&old_locks[i]);
        return CORE_ERR_MALLOC_FAILED;
    }

    for (size_t i = 0; i < old_bucket_count; ++i) {
        ConceptNode* current = old_buckets[i];
        while(current) {
            ConceptNode* next = current->next;
            size_t new_index = hash_string(current->name) % new_bucket_count;
            current->next = new_buckets[new_index]; new_buckets[new_index] = current;
            current = next;
        }
    }

    // Release old resources
    for(size_t i = 0; i < old_bucket_count; ++i) core_mutex_unlock(&old_locks[i]);
    for(size_t i = 0; i < old_bucket_count; ++i) core_mutex_destroy(&old_locks[i]);
    free(old_buckets);
    free(old_locks);
    
    // Install new resources
    kb->buckets = new_buckets;
    kb->bucket_locks = new_locks;
    kb->bucket_count = new_bucket_count;
    for(size_t i = 0; i < new_bucket_count; ++i) core_mutex_init(&kb->bucket_locks[i]);

    return CORE_OK;
}

//==============================================================================
// 4. MAIN DEMONSTRATION
//==============================================================================
void print_header(const char* title) {
    printf("\n\n---[ %s ]---\n", title);
}

void perform_query(CORE_KnowledgeBase* mind, const char* name) {
    printf("Querying for '%s'...\n", name);
    const CORE_HyperVector* pichai_hv = core_kb_get_vector(mind, "SundarPichai");
    const CORE_HyperVector* is_from_hv = core_kb_get_vector(mind, "is_from");
    if (!pichai_hv || !is_from_hv) {
        printf("\n‚ùå FAILURE: Could not retrieve base vectors for query.\n");
        return;
    }

    CORE_Arena* temp_arena = arena_create();
    CORE_HyperVector* query_vec = core_hv_create_unbind(pichai_hv, is_from_hv, temp_arena);
    CORE_SearchResult result = core_kb_find_closest_bruteforce(mind, query_vec, "SundarPichai");
    printf("   Closest matching concept in memory: '%s' (Distance: %u)\n", result.name, result.distance);
    if (strcmp(result.name, "India") == 0) {
        printf("\n‚úÖ SUCCESS: The mind correctly computed that Sundar Pichai is from India.\n");
    } else {
        printf("\n‚ùå FAILURE: The mind could not retrieve the correct fact via algebraic query.\n");
    }
    arena_destroy(temp_arena);
}

//==============================================================================
// 4. MAIN DEMONSTRATION (EXTENDED)
//==============================================================================


// Helper function to perform and validate a standard (Subject, Relation, ?) query
void perform_algebraic_query(CORE_KnowledgeBase* mind, const char* subject, const char* relation, const char* expected_object) {
    printf("Query: (%s, %s, ?) -> expecting '%s'\n", subject, relation, expected_object);
    
    const CORE_HyperVector* subject_hv = core_kb_get_vector(mind, subject);
    const CORE_HyperVector* relation_hv = core_kb_get_vector(mind, relation);

    if (!subject_hv || !relation_hv) {
        printf("\n   ‚ùå FAILURE: Could not retrieve base vectors for query.\n");
        return;
    }

    CORE_Arena* temp_arena = arena_create();
    // The query is to find X where: subject ‚âà bind(relation, X)
    // Algebraically, this means X ‚âà unbind(subject, relation)
    CORE_HyperVector* query_vec = core_hv_create_unbind(subject_hv, relation_hv, temp_arena);
    CORE_SearchResult result = core_kb_find_closest_bruteforce(mind, query_vec, subject);
    
    printf("   Closest matching concept in memory: '%s' (Distance: %u)\n", result.name, result.distance);
    
    if (strcmp(result.name, expected_object) == 0) {
        printf("   ‚úÖ SUCCESS: The mind correctly computed the answer.\n");
    } else {
        printf("   ‚ùå FAILURE: The mind could not retrieve the correct fact.\n");
    }
    arena_destroy(temp_arena);
}

int main(void) {
    const char* mind_filepath = "mind_state.core";
    print_header("C.O.R.E. V7.0 HARDENED REASONING DEMONSTRATION");

    CORE_Config config = {
        .dimensionality = 2048,
        .gravitational_constant = 10,
        .min_gravitational_distance = 100,
        .initial_buckets = 16,
        .resize_load_factor = 0.75,
        .seed = 42,
        .similarity_cache_size = 1024
    };
    CORE_KnowledgeBase* mind = core_kb_create(config);
    if (!mind) {
        printf("Fatal: Could not create knowledge base.\n");
        return 1;
    }
    printf("Mind initialized with D=%u and Seed=%llu.\n", config.dimensionality, (unsigned long long)config.seed);

    print_header("Phase 1: Knowledge Integration");
    CORE_BatchAssertion facts[] = {
        // Original fact set
        {"Elephant", "is_a", "Mammal", 50},
        {"Human", "is_a", "Mammal", 50},
        {"Ant", "is_an", "Insect", 50},
        {"Mammal", "has_property", "WarmBlood", 25},
        {"Mammal", "has_property", "Vertebrae", 25},
        {"Insect", "has_property", "Exoskeleton", 25},
        {"Insect", "has_property", "SixLegs", 25},
        {"SundarPichai", "is_from", "India", 100},
        {"India", "is_a", "Country", 50},
        {"Asia", "contains", "India", 25},
        // Extended fact set with Sam Altman
        {"SamAltman", "is_a", "Human", 100},
        {"SamAltman", "is_ceo_of", "OpenAI", 100},
        {"OpenAI", "develops", "ChatGPT", 50},
        {"ChatGPT", "is_a", "LLM", 25}
    };
    size_t num_facts = sizeof(facts) / sizeof(facts[0]);
    core_kb_assert_batch(mind, facts, num_facts);
    printf("Integrated %zu facts into the mind's resonant manifold.\n", num_facts);

    print_header("Phase 2: Verifying Conceptual Distance ('Common Sense')");
    const CORE_HyperVector* elephant_hv = core_kb_get_vector(mind, "Elephant");
    const CORE_HyperVector* human_hv = core_kb_get_vector(mind, "Human");
    const CORE_HyperVector* ant_hv = core_kb_get_vector(mind, "Ant");
    const CORE_HyperVector* altman_hv = core_kb_get_vector(mind, "SamAltman");

    uint32_t dist_elephant_human = core_kb_distance(mind, elephant_hv, human_hv);
    uint32_t dist_elephant_ant = core_kb_distance(mind, elephant_hv, ant_hv);
    printf("Distance (Elephant <-> Human): %u / %u\n", dist_elephant_human, config.dimensionality);
    printf("Distance (Elephant <-> Ant):   %u / %u\n", dist_elephant_ant, config.dimensionality);
    if (dist_elephant_human < dist_elephant_ant) {
        printf("   ‚úÖ SUCCESS: Mind correctly identifies 'Elephant' is conceptually closer to 'Human' than to 'Ant'.\n");
    } else {
        printf("   ‚ùå FAILURE: Mind's conceptual space is not structured correctly.\n");
    }

    uint32_t dist_altman_human = core_kb_distance(mind, altman_hv, human_hv);
    uint32_t dist_altman_ant = core_kb_distance(mind, altman_hv, ant_hv);
    printf("\nDistance (SamAltman <-> Human): %u / %u\n", dist_altman_human, config.dimensionality);
    printf("Distance (SamAltman <-> Ant):   %u / %u\n", dist_altman_ant, config.dimensionality);
    if (dist_altman_human < dist_altman_ant) {
        printf("   ‚úÖ SUCCESS: Mind correctly identifies 'SamAltman' is conceptually closer to 'Human' than to 'Ant'.\n");
    } else {
        printf("   ‚ùå FAILURE: Mind's conceptual space is not structured correctly for new concepts.\n");
    }

    print_header("Phase 3: Algebraic Query (Fact Retrieval)");
    perform_algebraic_query(mind, "SundarPichai", "is_from", "India");
    printf("\n");
    perform_algebraic_query(mind, "SamAltman", "is_ceo_of", "OpenAI");
    
    print_header("Phase 4: Persistence Test (Save)");
    CORE_Status save_status = core_kb_save(mind, mind_filepath);
    if (save_status == CORE_OK) {
        printf("‚úÖ SUCCESS: Mind state saved to '%s'.\n", mind_filepath);
    } else {
        printf("‚ùå FAILURE: Could not save mind state. Error: %s\n", core_status_to_string(save_status));
    }
    core_kb_destroy(mind);
    printf("Original mind object destroyed.\n");

    print_header("Phase 5: Persistence Test (Load)");
    CORE_Status load_status;
    CORE_KnowledgeBase* loaded_mind = core_kb_load(mind_filepath, &load_status);
    if (loaded_mind) {
        printf("‚úÖ SUCCESS: Mind state loaded from '%s'.\n", mind_filepath);
        CORE_Stats stats;
        core_kb_get_stats(loaded_mind, &stats);
        printf("   Loaded mind has %zu concepts and %zu assertions.\n", stats.concept_count, stats.assertion_count);

        print_header("Phase 6: Verifying Loaded State with Same Queries");
        perform_algebraic_query(loaded_mind, "SundarPichai", "is_from", "India");
        printf("\n");
        perform_algebraic_query(loaded_mind, "SamAltman", "is_ceo_of", "OpenAI");
        
        core_kb_destroy(loaded_mind);
    } else {
        printf("‚ùå FAILURE: Could not load mind state. Error: %s\n", core_status_to_string(load_status));
    }
    
    printf("\n\nEngine shutdown complete.\n");

    return 0;
}
